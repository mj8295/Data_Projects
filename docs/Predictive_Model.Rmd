---
title: "Predictive Model Training and Testing"
author: "Maximilian Johnson"
date: "11 June 2022"
output:
  html_document:
    df_print: paged
---



Part 1: Load data, libraries, and define functions for later use
```{r setup}
# Clears the Global Environment
rm(list = ls())

# Set work directory and read data into R
setwd('C:/Users/Max/Documents/MSBA/MSBA Fall B/MKT 436R/Assignment 3')
df <- read.csv('Student Data 5.csv')

# Loads earth package for use in the models
library(earth)
# Preserve raw data and rename table to an intuitive name
approval_data <- data.frame(df)

# Creates training data set, made up of a random 80% of the total data set
set.seed(3161)

is_training <- runif(nrow(approval_data)) < .8
training_data <- subset(approval_data, is_training)

# Creates validation data set made up of the records not used for training
validation_data <- subset(approval_data, !is_training)

# RMSE Function creation used to evaluate the accuracy of the model
get_detail_RMSE <- function(model){
  actualY <- validation_data$card
  predictedY <- predict(model, validation_data)
  return(mean((actualY - predictedY)^2)^.5)
}
```

Part 2a: Creating our predictive models
```{r Part 2a}
# First I want to run a MARS model so I can use the plotmo function to get more information
earth1 <- earth(card ~ reports + age + income + share + expenditure + owner + selfemp + dependents + months + majorcards + active, data = training_data)
plotmo(earth1)

# We see that share and reports appear to be parabolic so lets square them in our first regression model
model1.1 <- lm(card ~ reports^2 + age + income + share^2 + expenditure + owner + selfemp + dependents + months + majorcards + active, data = training_data)
get_detail_RMSE(model1.1)
```

--

Part 2b: Refining our predictive model using linear regression
```{r Part 2b}
#Now I will add an interaction between the non-linear terms we saw in the plotmo of earth1
model1.2 <- lm(card ~ (reports^2 * share^2) + age + income + expenditure + owner + selfemp + dependents + months + majorcards + share^2 + active, data = training_data)
model1.3 <- lm(card ~ (reports^2 * share^2) + age + income + expenditure + owner + selfemp + dependents + months + majorcards + (share^2 * active), data = training_data)
model1.4 <- lm(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + owner + selfemp + dependents + months + majorcards + (share^2 * active), data = training_data)

get_detail_RMSE(model1.2)
get_detail_RMSE(model1.3)
get_detail_RMSE(model1.4)
```
We see here that all interaction terms are effective at improving our model

--

Part 2c: Refining our predictive model using the MARS model
```{r Part 2c}
# Now lets begin using the MARS modelon our best regression so far (model1B.4)
model1.5 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + owner + selfemp + dependents + months + majorcards + (share^2 * active), data = training_data)
get_detail_RMSE(model1.5)
```
This improves the model so let's add degree and thresh terms to see if this helps the model's performance

--

Part 2d: Refining our predictive model by applying the degree argument
```{r Part 2d}
model1.6 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + owner + selfemp + dependents + months + majorcards + (share^2 * active), degree = 2, data = training_data)
get_detail_RMSE(model1.6)
```
We see that the degree term improves performance

--

Part 2e: Refining our predictive model by tweaking the thresh term
```{r Part 2e}
model1.7 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + owner + selfemp + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0, data = training_data)
model1.8 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + owner + selfemp + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0.1, data = training_data)
model1.9 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + owner + selfemp + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0.01, data = training_data)

get_detail_RMSE(model1.7)
get_detail_RMSE(model1.8)
get_detail_RMSE(model1.9)
```
Thresh being equal to 0 and degree equal to 2 is the best

--

Part 2f: Visualize each parameter's relationship to card to further refine model
```{r Part 2f}
plotmo(model1.7)
# From this we see additional interactions that we will add to the next model

model1.10 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0, data = training_data)
get_detail_RMSE(model1.10)
plotmo(model1.10)

# now lets add the new interactions we see form this latest plotmo
model1.11 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + (reports^2 * dependents) + (owner * dependents) + months + (majorcards * owner) + (majorcards * selfemp) + (share^2 * active), degree = 2, thresh = 0, data = training_data)
get_detail_RMSE(model1.11)

# This improved predictive ability so we will keep this
# lets try adding factor terms to owner, selfemp and majorcard
model1.12 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + (reports^2 * factor(owner)) + (factor(owner) * share^2) + (factor(selfemp) * factor(owner)) + dependents + months + factor(majorcards) + (share^2 * active), degree = 2, thresh = 0, data = training_data)

get_detail_RMSE(model1.12)
# This didnt help so again we will stick with model1B.10
# Lets start deleting out terms one by one to see if that helps
model1.13 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + income + expenditure + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0, data = training_data)
model1.14 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + expenditure + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0, data = training_data)
model1.15 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0, data = training_data)
model1.16 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + months + majorcards + (share^2 * active), degree = 2, thresh = 0, data = training_data)
model1.17 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + dependents + majorcards + (share^2 * active), degree = 2, thresh = 0, data = training_data)

get_detail_RMSE(model1.13)
get_detail_RMSE(model1.14)
get_detail_RMSE(model1.15)
get_detail_RMSE(model1.16)
get_detail_RMSE(model1.17)
# Model 15 did better here so we well drop expense and add poly to age to see if this improves anything
model1.18 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + poly(age,3) + income + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0, data = training_data)
get_detail_RMSE(model1.18)

# The improvement here was very small so we will stick with this for as the final model
```


Part 2g: K-fold Cross validation

We will do a final k-fold cross validation for our best models to double check and make sure model1B.18 is the best as there are several models with near identical RMSE scores
```{r Part 2g}

nFold = 5
model_performance <- matrix(NA, nFold, 3)

for(fold in 1:nFold){
  val_num <- floor(runif(nrow(approval_data))*nFold) + 1
  
  
  training_data <- subset(approval_data, val_num != fold)
  validation_data <- subset(approval_data, val_num == fold)
  
  model1.10 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0, data = training_data)
  model1.11 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + age + income + expenditure + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + (reports^2 * dependents) + (owner * dependents) + months + (majorcards * owner) + (majorcards * selfemp) + (share^2 * active), degree = 2, thresh = 0, data = training_data)
  model1.18 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + poly(age,3) + income + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0, data = training_data)
  
  valid1 = mean((validation_data$card -
                   predict(model1.10,validation_data))^2)^.5
  valid2 = mean((validation_data$card -
                   predict(model1.11,validation_data))^2)^.5
  valid3 = mean((validation_data$card -
                   predict(model1.18,validation_data))^2)^.5
  model_performance[fold, ] <- c(valid1, valid2, valid3)
}

colMeans(model_performance)

#Now we see that model 10 is the best so we will go with that one as our final answer and train it on the whole dataset
model1 <- earth(card ~ (reports^2 * share^2) + (reports^2 * active) + poly(age,3) + income + (reports^2 * owner) + (owner * share^2) + (selfemp * owner) + dependents + months + majorcards + (share^2 * active), degree = 2, thresh = 0, data = approval_data)

```


```{r, include=FALSE}
#This reduces the file size in some cases fringe cases
model1$cv.list = NULL
model1$cv.oof.fit.tab = NULL
model1$varmod = NULL

save(model1, file = paste0('Predictive Modeling and Evaluation.Rdata'))
```